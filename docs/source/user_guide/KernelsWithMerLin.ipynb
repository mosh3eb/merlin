{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8bfd645",
   "metadata": {},
   "source": [
    "# Quantum Kernel: Practical Guide\n",
    "\n",
    "This notebook provides a didactic tour of MerLin's quantum kernel, using multiple datasets and construction methods.\n",
    "We'll compute precomputed kernel matrices and train classical SVMs, and also show a short training loop with NKernelAlignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03db2d3f",
   "metadata": {},
   "source": [
    "## Setup and helpers"
   ]
  },
  {
   "cell_type": "code",
   "id": "7c652f3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T17:25:40.617619Z",
     "start_time": "2025-09-15T17:25:38.803914Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from merlin.algorithms.kernels import FidelityKernel, FeatureMap, KernelCircuitBuilder\n",
    "from merlin.algorithms.loss import NKernelAlignment\n",
    "from merlin.core.photonicbackend import PhotonicBackend\n",
    "from merlin.core.generators import CircuitType\n",
    "\n",
    "# Reproducibility\n",
    "rng = np.random.RandomState(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "def evaluate_kernel(kernel, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "        Compute precomputed kernel matrices and return accuracy.\n",
    "    \"\"\"\n",
    "    X_train_t = torch.tensor(X_train, dtype=torch.float32)\n",
    "    X_test_t = torch.tensor(X_test, dtype=torch.float32)\n",
    "    K_train = kernel(X_train_t).detach().numpy()\n",
    "    K_test = kernel(X_test_t, X_train_t).detach().numpy()\n",
    "    clf = SVC(kernel=\"precomputed\", random_state=42)\n",
    "    clf.fit(K_train, y_train)\n",
    "    return clf.score(K_test, y_test)\n",
    "\n",
    "def check_kernel_properties(K):\n",
    "    \"\"\"\n",
    "        Basic properties for sanity checking.\n",
    "    \"\"\"\n",
    "    assert K.shape[0] == K.shape[1]\n",
    "    assert np.allclose(K, K.T, atol=1e-6), \"Kernel must be symmetric\"\n",
    "    # Diagonal close to 1, within tolerance\n",
    "    assert np.allclose(np.diag(K), 1.0, atol=1e-1)\n",
    "    return True\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "d40d4047",
   "metadata": {},
   "source": [
    "## Iris (multi-class) — quickstart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a176b4b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris accuracy: 1.000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "kernel = FidelityKernel.simple(\n",
    "    input_size=4,      # number of features\n",
    "    n_modes=6,         # photonic modes\n",
    "    n_photons=2,       # photons (<= n_modes)\n",
    "    circuit_type=\"series\",\n",
    "    reservoir_mode=False,\n",
    "    force_psd=True,    # project to PSD if needed\n",
    ")\n",
    "# Evaluate\n",
    "X_train_t = torch.tensor(X_train, dtype=torch.float32)\n",
    "K_train = kernel(X_train_t).detach().numpy()\n",
    "_ = check_kernel_properties(K_train)\n",
    "acc = evaluate_kernel(kernel, X_train, X_test, y_train, y_test)\n",
    "print(f'Iris accuracy: {acc:.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5367d03a",
   "metadata": {},
   "source": [
    "## Iris — custom Perceval circuit (advanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8c270f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris (custom circuit) accuracy: 0.967\n",
      "Note: deep circuits may require larger tolerances due to numerical chains.\n"
     ]
    }
   ],
   "source": [
    "import perceval as pcvl\n",
    "\n",
    "def create_quantum_circuit(m, size=400):\n",
    "    wl = pcvl.GenericInterferometer(\n",
    "        m,\n",
    "        lambda i: pcvl.BS() // pcvl.PS(pcvl.P(f'phase_1_{i}')) // pcvl.BS() // pcvl.PS(pcvl.P(f'phase_2_{i}')),\n",
    "        shape=pcvl.InterferometerShape.RECTANGLE,\n",
    "    )\n",
    "    c = pcvl.Circuit(m)\n",
    "    c.add(0, wl, merge=True)\n",
    "    c_var = pcvl.Circuit(m)\n",
    "    for i in range(size):\n",
    "        px = pcvl.P(f'px-{i + 1}')\n",
    "        c_var.add(i % m, pcvl.PS(px))\n",
    "    c.add(0, c_var, merge=True)\n",
    "    wr = pcvl.GenericInterferometer(\n",
    "        m,\n",
    "        lambda i: pcvl.BS() // pcvl.PS(pcvl.P(f'phase_3_{i}')) // pcvl.BS() // pcvl.PS(pcvl.P(f'phase_4_{i}')),\n",
    "        shape=pcvl.InterferometerShape.RECTANGLE,\n",
    "    )\n",
    "    c.add(0, wr, merge=True)\n",
    "    return c\n",
    "\n",
    "def get_quantum_kernel(modes=10, input_size=4, photons=4, no_bunching=False):\n",
    "    circuit = create_quantum_circuit(m=modes, size=input_size)\n",
    "    feature_map = FeatureMap(\n",
    "        circuit=circuit,\n",
    "        input_size=input_size,\n",
    "        input_parameters=['px'],\n",
    "        trainable_parameters=['phase'],\n",
    "        dtype=torch.float64,\n",
    "    )\n",
    "    input_state = [0] * modes\n",
    "    for p in range(min(photons, modes // 2)):\n",
    "        input_state[2 * p] = 1\n",
    "    return FidelityKernel(\n",
    "        feature_map=feature_map,\n",
    "        input_state=input_state,\n",
    "        no_bunching=no_bunching,\n",
    "        force_psd=True,\n",
    "    )\n",
    "\n",
    "acc_custom = evaluate_kernel(\n",
    "    get_quantum_kernel(input_size=4, modes=10, photons=4),\n",
    "    X_train, X_test, y_train, y_test\n",
    ")\n",
    "print(f'Iris (custom circuit) accuracy: {acc_custom:.3f}')\n",
    "print('Note: deep circuits may require larger tolerances due to numerical chains.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053b6075",
   "metadata": {},
   "source": [
    "## Iris (binary) — training with NKernelAlignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65384afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris binary accuracy (after short training): 1.000\n"
     ]
    }
   ],
   "source": [
    "# Binary subset: classes 0 vs 1\n",
    "mask = y < 2\n",
    "X_b, y_b = X[mask], y[mask]\n",
    "y_b_signed = 2 * y_b - 1  # {-1, +1}\n",
    "Xtr, Xte, ytr, yte = train_test_split(X_b, y_b_signed, test_size=0.3, random_state=42, stratify=y_b_signed)\n",
    "\n",
    "Xtr_t = torch.tensor(Xtr, dtype=torch.float64)\n",
    "Xte_t = torch.tensor(Xte, dtype=torch.float64)\n",
    "ytr_t = torch.tensor(ytr, dtype=torch.float32)\n",
    "\n",
    "kernel_t = FidelityKernel.simple(input_size=4, n_modes=6, n_photons=2)\n",
    "opt = torch.optim.Adam(kernel_t.parameters(), lr=1e-2)\n",
    "loss_fn = NKernelAlignment()\n",
    "for _ in range(3):\n",
    "    opt.zero_grad()\n",
    "    K = kernel_t(Xtr_t)\n",
    "    loss = loss_fn(K, ytr_t)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "\n",
    "Ktr = kernel_t(Xtr_t).detach().numpy()\n",
    "Kte = kernel_t(Xte_t, Xtr_t).detach().numpy()\n",
    "clf = SVC(kernel=\"precomputed\", random_state=42)\n",
    "clf.fit(Ktr, ((ytr + 1) // 2))\n",
    "acc_bin = clf.score(Kte, ((yte + 1) // 2))\n",
    "print(f'Iris binary accuracy (after short training): {acc_bin:.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350684f2",
   "metadata": {},
   "source": [
    "## Wine (multi-class) — backend and builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38ddf821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wine (backend) accuracy: 0.867\n",
      "Wine (builder) accuracy: 0.867\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "\n",
    "wine = load_wine()\n",
    "Xw, yw = wine.data, wine.target  # 13 features\n",
    "Xw_tr, Xw_te, yw_tr, yw_te = train_test_split(Xw, yw, test_size=0.25, random_state=42, stratify=yw)\n",
    "\n",
    "# Method 1: From PhotonicBackend\n",
    "backend = PhotonicBackend(circuit_type=CircuitType.SERIES, n_modes=8, n_photons=3, reservoir_mode=True)\n",
    "kernel_backend = FidelityKernel.from_photonic_backend(input_size=13, photonic_backend=backend)\n",
    "acc_backend = evaluate_kernel(kernel_backend, Xw_tr, Xw_te, yw_tr, yw_te)\n",
    "print(f'Wine (backend) accuracy: {acc_backend:.3f}')\n",
    "\n",
    "# Method 2: Builder pattern\n",
    "builder = KernelCircuitBuilder()\n",
    "kernel_builder = (builder\n",
    "    .input_size(13)\n",
    "    .n_modes(8)\n",
    "    .n_photons(3)\n",
    "    .circuit_type(CircuitType.SERIES)\n",
    "    .reservoir_mode(True)\n",
    "    .build_fidelity_kernel()\n",
    ")\n",
    "acc_builder = evaluate_kernel(kernel_builder, Xw_tr, Xw_te, yw_tr, yw_te)\n",
    "print(f'Wine (builder) accuracy: {acc_builder:.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d404f1",
   "metadata": {},
   "source": [
    "## Breast Cancer (binary) — small sample demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e0dbf31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breast Cancer (subset) accuracy: 0.550\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "Xc, yc = cancer.data, cancer.target\n",
    "Xc_tr, Xc_te, yc_tr, yc_te = train_test_split(Xc, yc, test_size=0.2, random_state=42, stratify=yc)\n",
    "\n",
    "# Keep a small subset to keep computations light in docs builds\n",
    "Xc_tr_s, yc_tr_s = Xc_tr[:40], yc_tr[:40]\n",
    "Xc_te_s, yc_te_s = Xc_te[:20], yc_te[:20]\n",
    "\n",
    "kernel_cancer = FidelityKernel.simple(input_size=Xc.shape[1], n_modes=12, n_photons=6, reservoir_mode=True)\n",
    "acc_cancer = evaluate_kernel(kernel_cancer, Xc_tr_s, Xc_te_s, yc_tr_s, yc_te_s)\n",
    "print(f'Breast Cancer (subset) accuracy: {acc_cancer:.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c813d9",
   "metadata": {},
   "source": [
    "## Tips: PSD projection and numerical stability\n",
    "\n",
    "- Set `force_psd=True` to project symmetric kernels to positive semi-definite.\n",
    "- Deep custom circuits can accumulate numerical error; relax tolerances when checking properties like diagonal ≈ 1.\n",
    "- Use `reservoir_mode=True` for non-trainable, stable kernels; disable for trainable kernels with `NKernelAlignment`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "merlin-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
